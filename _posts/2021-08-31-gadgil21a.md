---
abstract: Medical image segmentation models are typically supervised by expert annotations
  at the pixel-level, which can be expensive to acquire. In this work, we propose
  a method that combines the high quality of pixel-level expert annotations with the
  scale of coarse DNN-generated saliency maps for training multi-label semantic segmentation
  models. We demonstrate the application of our semi-supervised method, which we call
  CheXseg, on multi-label chest X-ray interpretation. We find that CheXseg improves
  upon the performance (mIoU) of fully-supervised methods that use only pixel-level
  expert annotations by 9.7% and weakly-supervised methods that use only DNN-generated
  saliency maps by 73.1%. Our best method is able to match radiologist agreement on
  three out of ten pathologies and reduces the overall performance gap by 57.2% as
  compared to weakly-supervised methods.
booktitle: Medical Imaging with Deep Learning
title: 'CheXseg: Combining Expert Annotations with DNN-generated Saliency Maps for
  X-ray Segmentation'
openreview: eA7PGMYmHFA
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gadgil21a
month: 0
tex_title: 'CheXseg: Combining Expert Annotations with {DNN}-generated Saliency Maps
  for X-ray Segmentation'
firstpage: 190
lastpage: 204
page: 190-204
order: 190
cycles: false
bibtex_author: Gadgil, Soham Uday and Endo, Mark and Wen, Emily and Ng, Andrew Y.
  and Rajpurkar, Pranav
author:
- given: Soham Uday
  family: Gadgil
- given: Mark
  family: Endo
- given: Emily
  family: Wen
- given: Andrew Y.
  family: Ng
- given: Pranav
  family: Rajpurkar
date: 2021-08-31
address:
container-title: Proceedings of the Fourth Conference on Medical Imaging with Deep
  Learning
volume: '143'
genre: inproceedings
issued:
  date-parts:
  - 2021
  - 8
  - 31
pdf: https://proceedings.mlr.press/v143/gadgil21a/gadgil21a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
